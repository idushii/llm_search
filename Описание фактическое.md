# Подробное описание проекта "Mind Search"

## Общее назначение

"Mind Search" представляет собой интеллектуальную систему поиска и обработки информации, разработанную для глубокого и всестороннего анализа заданных тем. Система выполняет многоуровневый поиск по запросу пользователя, обрабатывает найденную информацию и генерирует структурированный, содержательный ответ на основе наиболее релевантных источников.

## Архитектура системы

Система построена по модульному принципу и включает следующие основные компоненты:

### 1. Модули обработки данных

- **Core (Ядро)** - базовые компоненты и утилиты:
  - `config.py` - конфигурация и переменные окружения
  - `constants.py` - константы проекта
  - `utils.py` - вспомогательные функции (хеширование, форматирование, логирование)

- **Search (Поиск)** - компоненты, ответственные за поиск информации:
  - `planned_topics.py` - планирование подзапросов на основе исходного запроса
  - `planned_searching.py` - генерация поисковых запросов для каждого подзапроса
  - `scraping.py` - выполнение поисковых запросов и скрапинг веб-страниц

- **Processing (Обработка)** - компоненты для обработки найденной информации:
  - `ranking_search_result.py` - ранжирование результатов поиска
  - `summarizer.py` - создание сжатых саммари документов
  - `ranking_summary.py` - ранжирование саммари по релевантности
  - `nlp_utils.py` - генерация итогового структурированного ответа

- **Storage (Хранение)** - управление данными и кэширование:
  - `cache_manager.py` - управление кэшированием данных
  - `file_system.py` - работа с файловой системой проекта

### 2. Структура каталогов

```
/project/
    /src/
        /core/        - базовые компоненты
        /search/      - модули поиска
        /processing/  - модули обработки
        /storage/     - модули управления данными
    /cache/           - кэш данных
        /docs/        - кэшированные документы
        /search_queries/  - кэшированные поисковые запросы
        /search_results/  - кэшированные результаты поиска
        /ranked_results/  - кэшированные ранжированные результаты
        /ranked_summaries/ - кэшированные ранжированные саммари
    main.py           - точка входа в приложение
    requirements.txt  - зависимости
    .env.example      - шаблон переменных окружения
    .gitignore        - исключения для Git
    README.md         - документация
```

## Принцип работы

Система работает в несколько последовательных этапов:

### 1. Планирование запросов

- Пользователь вводит исходный запрос через консольный интерфейс
- `TopicPlanner` анализирует запрос с помощью LLM и генерирует подзапросы (до 3-х), охватывающие различные аспекты темы, используя специальный промпт:
  ```
Ты – ассистент, который составляет до 3 подзапросов для поиска в интернете по заданной теме. Твои подзапросы должны соответствовать следующим критериям:

Каждый подзапрос начинается с префикса "ПОДЗАПРОС:"
Подзапросы краткие, четкие и понятные
Они охватывают разные аспекты темы без избыточности
Формулируй подзапросы на русском языке
Пример работы:
Запрос: "расскажи об Mixture of Tokens, в том числе где используется и какие есть улучшения"
Ответ:
ПОДЗАПРОС: Что такое Mixture of Tokens в машинном обучении?
ПОДЗАПРОС: Где используется Mixture of Tokens и какие задачи решает?
ПОДЗАПРОС: Какие есть улучшения Mixture of Tokens и их преимущества?

Составь подзапросы в таком формате.
  ```
- Пользователь может просмотреть и отредактировать сгенерированные подзапросы
- `SearchQueryPlanner` создает поисковые запросы для каждого подзапроса на русском и английском языках, используя другой специализированный промпт:
  ```
Ты – интеллектуальный помощник, который составляет поисковые запросы на русском и английском языках. 
Твоя задача – создать до 3 запросов на обеих языках по заданной теме. 
Формат каждого запроса:

- Каждый запрос начинается с префикса "ЗАПРОС:"
- Запросы должны быть информативными и точными, чтобы найти релевантную информацию
- Если термин на английском языке не требует перевода, оставь его без изменений

Пример вывода для темы "Mixture of Tokens в машинном обучении":

ЗАПРОС: Что такое Mixture of Tokens в машинном обучении?
ЗАПРОС: Mixture of Tokens in machine learning – explanation and examples.
  ```

### 2. Поиск информации

- `SearchEngine` выполняет поисковые запросы через API поисковой системы SearchXNG с применением Rate Limiting для соблюдения ограничений API
- Для каждого запроса собираются метаданные результатов (заголовок, URL, сниппет)
- Производится скрапинг содержимого найденных веб-страниц с использованием сервиса r.jina.ai, который возвращает уже готовый очищенный текст в формате Markdown
- Полученный Markdown-контент сохраняется в кэш без дополнительной обработки
- В случае ошибок при скрапинге через r.jina.ai имеется резервный механизм прямого скрапинга и преобразования HTML в Markdown

### 3. Ранжирование результатов

- `SearchResultRanker` оценивает релевантность каждого результата исходному запросу с использованием LLM
- Ранжирование выполняется на основе пяти критериев, каждый оценивается по шкале от 0 до 10:
  1. **Соответствие исходному запросу** – насколько документ отвечает на поставленный вопрос
  2. **Соответствие направлению поиска** – насколько документ соответствует текущему подзапросу
  3. **Полнота информации** – охватывает ли документ ключевые аспекты темы
  4. **Точность** – содержит ли документ корректные и актуальные данные
  5. **Читабельность и структура** – насколько текст логично организован
- В случае ошибок при обращении к LLM предусмотрен резервный алгоритм ранжирования на основе ключевых слов
- Фильтруются дубликаты и низкокачественные результаты
- Выбираются топ-5 наиболее релевантных документов для дальнейшей обработки
- Результаты ранжирования сохраняются в кэш для повторного использования

### 4. Саммаризация документов

- `DocumentSummarizer` передает скачанный Markdown-текст языковой модели для саммаризации
- Для каждого документа генерируется сжатое саммари, выделяющее ключевую информацию, согласно промпту:
  ```
Роль: Ты — интеллектуальный ассистент, специализирующийся на анализе и кратком изложении текстов. Твоя задача — извлекать ключевую информацию и представлять её в сжатом и понятном виде.

Требования к summary:

Сжатость: Используй только важные факты, избегая лишних деталей.
Ясность: Формулируй мысли четко и логично, избегая двусмысленности.
Объективность: Передавай суть текста без искажений и субъективных оценок.
Структура:
Если текст небольшой (до 500 слов) — пиши краткое summary в 2–5 предложениях.
Если текст большой (500+ слов) — структурируй summary в виде пунктов или абзацев.
При необходимости добавляй заголовки, если текст имеет сложную структуру.
Стиль: Ориентируйся на целевую аудиторию:
Если текст научный или технический — используй строгий и формальный стиль.
Если текст новостной — передавай основные факты кратко и объективно.
Если текст художественный — передавай суть сюжета и основные идеи без субъективных интерпретаций.

Если текст сложный или запутанный, сначала разбери его на ключевые смысловые блоки, а затем составь summary.
  ```
- Саммари сохраняются в кэш для повторного использования

### 5. Ранжирование саммари

- `SummaryRanker` оценивает релевантность каждого саммари исходному запросу с использованием LLM
- Ранжирование выполняется по пяти критериям:
  1. **Соответствие исходному запросу** – насколько саммари отвечает на поставленный вопрос
  2. **Полнота информации** – охватывает ли саммари ключевые аспекты темы
  3. **Точность информации** – содержит ли саммари корректные и актуальные данные
  4. **Информативность** – сколько полезной информации содержится в саммари
  5. **Читабельность и структура** – насколько саммари логично организовано
- В случае ошибок при обращении к LLM используется резервный алгоритм ранжирования на основе ключевых слов
- Итоговая оценка каждого саммари рассчитывается как среднее значение по всем критериям
- Выбираются топ-5 наиболее информативных саммари
- Результаты ранжирования сохраняются в кэш для повторного использования

### 6. Генерация ответа

- `AnswerGenerator` объединяет информацию из лучших саммари
- Формирует промпт для LLM, включающий:
  - Исходный запрос пользователя
  - Контекст из топ-5 саммари
  - Требования к структуре и формату ответа
- Создается структурированный ответ в формате Markdown с разделами и подразделами
- Формируется список использованных источников с URL
- Ответ и исходный запрос сохраняются в кэш

### 7. Кэширование и управление данными

- `CacheManager` сохраняет все промежуточные результаты в кэш
- Система использует следующую структуру кэширования:
  - `/cache/search_queries/` - кэшированные поисковые запросы
  - `/cache/search_results/` - кэшированные результаты поиска
  - `/cache/docs/` - кэшированные документы
  - `/cache/ranked_results/` - кэшированные ранжированные результаты
  - `/cache/ranked_summaries/` - кэшированные ранжированные саммари
- `FileSystemManager` обеспечивает работу с файловой системой (экспорт/импорт, удаление)
- Система автоматически очищает устаревшие данные кэша после указанного периода времени (по умолчанию 30 дней)
- Предусмотрена возможность получения подробной статистики по кэшу

## Технические особенности

### API и интеграции

- **LLM API** (AITUNNEL_API_KEY) - используется для:
  - Генерации подзапросов
  - Генерации поисковых запросов
  - Ранжирования результатов поиска
  - Саммаризации документов
  - Ранжирования саммари
  - Создания итогового ответа

- **SearchXNG API** - поисковая система для выполнения запросов

- **Jina AI API (r.jina.ai)** - используется для скрапинга веб-страниц и преобразования их в чистый Markdown-текст, что исключает необходимость дополнительной обработки HTML

### Ограничение нагрузки (Rate Limiting)

- Встроенный механизм ограничения частоты запросов к API:
  - SearchXNG: до 10 запросов в минуту (настраивается через LIMIT_SEARCHXNG_RPM)
  - Jina AI: до 5 запросов в секунду (настраивается через LIMIT_JINA_RPS)
  - AITUNNEL: до 2 запросов в секунду (настраивается через LIMIT_AITUNNEL_RPS)

### Асинхронная обработка

- Использование `asyncio` и `aiohttp` для параллельного выполнения запросов
- Применение семафоров для контроля одновременных запросов к каждому сервису
- Повышенная эффективность при работе с множественными запросами

### Интеллектуальное ранжирование через LLM

- Ранжирование результатов поиска с помощью языковой модели по пяти критериям с оценкой от 0 до 10
- Ранжирование саммари также выполняется с использованием языковой модели по пяти критериям
- Резервные алгоритмы ранжирования на основе ключевых слов на случай ошибок при обращении к LLM
- Итоговая оценка рассчитывается как среднее значение по всем критериям

### Кэширование и управление данными

- Структурированное кэширование всех этапов обработки через специальные директории
- Уникальные идентификаторы тем на основе запроса и хеша
- Автоматическая очистка устаревших данных
- Детальная статистика использования кэша
- Система .gitignore для контроля версий, сохраняющая структуру директорий, но исключающая содержимое кэша

## Практическое применение

Система особенно эффективна для:

1. **Исследования сложных тем**, требующих анализа множества источников
2. **Образовательных целей**, когда необходимо получить структурированную информацию по определенной теме
3. **Аналитической работы**, когда требуется обработать большие объемы информации из интернета
4. **Подготовки материалов** для статей, докладов, презентаций

## Технические требования

- **Python 3.8+**
- **API ключи**:
  - AITUNNEL_API_KEY для доступа к языковой модели
  - AITUNNEL_MODEL для указания используемой модели
  - SEARCHXNG_BASIC_AUTH_LOGIN и SEARCHXNG_BASIC_AUTH_PASSWORD для доступа к поисковой системе
- **Зависимости**:
  - requests==2.31.0
  - python-dotenv==1.0.0
  - aiohttp==3.8.5
  - asyncio==3.4.3

## Ограничения и особенности использования

- Требуется стабильное интернет-соединение
- Производительность зависит от доступности и быстродействия внешних API
- Количество запросов ограничено лимитами API-сервисов
- Качество итогового ответа зависит от качества найденных источников
- Для обработки результатов поиска и ранжирования используется LLM, что обеспечивает высокое качество оценки, но увеличивает стоимость запросов
- Конфигурируемые параметры позволяют настраивать работу системы под конкретные требования

## Пример процесса работы

### Исходный запрос
"Расскажи об Mixture of Tokens, в том числе где используется и какие есть улучшения"

### Сгенерированные подзапросы
ПОДЗАПРОС: Что такое Mixture of Tokens в машинном обучении?
ПОДЗАПРОС: Где используется Mixture of Tokens и какие задачи решает?
ПОДЗАПРОС: Какие есть улучшения Mixture of Tokens и их преимущества?

### Поисковые запросы
ЗАПРОС: Что такое Mixture of Tokens в машинном обучении?
ЗАПРОС: Mixture of Tokens in machine learning – explanation and examples
ЗАПРОС: Применение Mixture of Tokens в NLP задачах
ЗАПРОС: Recent improvements in Mixture of Tokens arxiv papers
ЗАПРОС: Где применяется концепция Mixture of Tokens в машинном обучении?
ЗАПРОС: Research paper on Mixture of Experts (MoE) models in machine learning applications

### Итоговый ответ
Система формирует структурированный ответ в формате Markdown на основе отранжированных через LLM саммари, включающий введение, основные разделы по теме и список использованных источников.
